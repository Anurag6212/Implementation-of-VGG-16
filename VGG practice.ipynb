{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 05 14:33:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 451.67       Driver Version: 451.67       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   36C    P8    N/A /  N/A |     77MiB /  4096MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'D:\\ineuron intelligence files\\archive\\Cotton Disease\\train'\n",
    "valid_path = r'D:\\ineuron intelligence files\\archive\\Cotton Disease\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(r'D:\\ineuron intelligence files\\archive\\Cotton Disease\\train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ineuron intelligence files\\\\archive\\\\Cotton Disease\\\\train\\\\diseased cotton leaf',\n",
       " 'D:\\\\ineuron intelligence files\\\\archive\\\\Cotton Disease\\\\train\\\\diseased cotton plant',\n",
       " 'D:\\\\ineuron intelligence files\\\\archive\\\\Cotton Disease\\\\train\\\\fresh cotton leaf',\n",
       " 'D:\\\\ineuron intelligence files\\\\archive\\\\Cotton Disease\\\\train\\\\fresh cotton plant']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg16.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 100356    \n",
      "=================================================================\n",
      "Total params: 14,815,044\n",
      "Trainable params: 100,356\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1951 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory(r'D:\\ineuron intelligence files\\archive\\Cotton Disease\\train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(r'D:\\ineuron intelligence files\\archive\\Cotton Disease\\test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 264s 4s/step - loss: 0.3076 - accuracy: 0.8903 - val_loss: 0.2244 - val_accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.3-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\users\\sai\\anaconda3\\envs\\tf2\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in d:\\users\\sai\\anaconda3\\envs\\tf2\\lib\\site-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\users\\sai\\anaconda3\\envs\\tf2\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\users\\sai\\anaconda3\\envs\\tf2\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in d:\\users\\sai\\anaconda3\\envs\\tf2\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 3, 2, 2, 3, 1, 3, 0, 3, 3, 3, 3, 0, 2, 2, 0, 3, 2, 2, 0,\n",
       "       3, 3, 3, 0, 2, 1, 3, 3, 1, 2, 1, 2, 1, 1, 0, 1, 2, 3, 2, 2, 0, 2,\n",
       "       1, 3, 1, 3, 0, 3, 2, 0, 3, 3, 1, 3, 3, 0, 2, 0, 1, 2, 0, 2, 1, 1,\n",
       "       3, 2, 3, 0, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 3, 2,\n",
       "       0, 1, 3, 3, 3, 1, 1, 1, 0, 3, 0, 1, 1, 0, 2, 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('D:\\\\ineuron intelligence files\\\\archive\\\\Cotton Disease\\\\test\\\\fresh cotton leaf\\\\d (7)_iaip.jpg', target_size = (224,224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.argmax(model.predict(test_image),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6558215e-04, 3.1674812e-08, 9.9983418e-01, 1.8472241e-07]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.tolist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#for index\n",
    "N = 0\n",
    "for num in range(len(result)) :\n",
    "    if result[num] > N :\n",
    "        N = result[num]\n",
    "print(result.index(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest element present in given array: 0.9998341798782349 And it belongs to freash_leaf class.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result1=[\"diseased_leaf\",\"diseased_plant\",\"freash_leaf\",\"freash_plant\"]\n",
    "max = result[0];\n",
    "i = 0;    \n",
    "     \n",
    "#Loop through the array    \n",
    "for index, value in enumerate(result):    \n",
    "    #Compare elements of array with max    \n",
    "    if(value > max):    \n",
    "        max = value;    \n",
    "        i = index   \n",
    "print(\"Largest element present in given array: \" + str(max) +\" And it belongs to \" +str(result1[i]) +\" class.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freash_leaf\n"
     ]
    }
   ],
   "source": [
    "#experiment\n",
    "#training_set.class_indices\n",
    "result1=[\"diseased_leaf\",\"diseased_plant\",\"freash_leaf\",\"freash_plant\"]\n",
    "\n",
    "max = result[0];\n",
    "i = 0;    \n",
    "     \n",
    "#Loop through the array    \n",
    "for index, value in enumerate(result):    \n",
    "    #Compare elements of array with max    \n",
    "    if(value > max):    \n",
    "        max = value;    \n",
    "        i = index  \n",
    "        print(str(result1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
